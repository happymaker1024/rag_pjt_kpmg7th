{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb338003-1bf9-4382-a5fd-ac6cc184bce3",
   "metadata": {},
   "source": [
    "# 와인 리뷰데이터 인덱싱\n",
    "- 벡터 DB : pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dabfc6-8798-4757-9392-f3a68014448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load_dotenv(dotenv_path=\"../.env\")\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "HF_EMBEDDING_MODEL = \"llama-text-embed-v2\"\n",
    "# PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_INDEX_NAME = \"wine-review2\"\n",
    "PINECONE_NAMESPACE = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "# PINECONE_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358dbe6-a1ba-484f-bd56-72df457689a3",
   "metadata": {},
   "source": [
    "# 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58dd0cd9-36dd-442e-b538-2e182e36429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "import os\n",
    "\n",
    "csv_path = os.path.abspath(\"wine_reviews/winemag-data-130k-v2.csv\")\n",
    "loader = CSVLoader(csv_path, encoding=\"latin-1\")   # 또는 \"ISO-8859-1\")\n",
    "docs = loader.load()\n",
    "\n",
    "# \"prepare/wine_reviews/winemag-data-130k-v2.csv\"\n",
    "# loader = CSVLoader('./wine_reviews/winemag-data-130k-v2.csv')\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d850e70-b01d-4cdb-9d55-643ee5dc319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0dbd86-3a78-4ec5-aa39-e5c38af85696",
   "metadata": {},
   "source": [
    "# Embedding 모델 객체 생성\n",
    "- huggingface 모델 사용 : `llama-text-embed-v2`\n",
    "- gpu 버전 : pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "- pip install sentence-transformers\n",
    "- pip install transformers==4.47.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632eaad2-b69a-4350-ab43-b5d10d9cfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "\n",
    "# 1. 임베딩 모델 로드\n",
    "model = SentenceTransformer(\n",
    "    \"nvidia/llama-nemotron-embed-1b-v2\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24447dc-3389-4c09-9380-3527b3e48451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 차원: 2048\n"
     ]
    }
   ],
   "source": [
    "# 모델 정보 확인\n",
    "print(f\"임베딩 차원: {model.get_sentence_embedding_dimension()}\")  # 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41239648-1ddb-45fe-afe8-bbadf6c2f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import time\n",
    "\n",
    "# 임베딩 모델 로드\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nvidia/llama-nemotron-embed-1b-v2\",\n",
    "    model_kwargs={\n",
    "        # 'device': 'cpu',\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True  \n",
    "    },  # GPU 사용\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0009ceb-6548-4590-8c5d-fee226f02629",
   "metadata": {},
   "source": [
    "# Pinecone객체, index객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa26442f-a169-4697-93ed-872be3515814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Pinecone 클라이언트를 초기화(객체생성)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0f6ace-2180-4d85-9bce-8a9bed25928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'wine-review2' already exists.\n"
     ]
    }
   ],
   "source": [
    "# pinecone에 index list 가져오기\n",
    "existing_indexes = pc.list_indexes()\n",
    "\n",
    "# 이름만 추출\n",
    "index_names = [index['name'] for index in existing_indexes.indexes]\n",
    "# print(index_names)\n",
    "\n",
    "# index 이름이 존재 하지 않으면 생성\n",
    "if PINECONE_INDEX_NAME not in index_names:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=2048,  # 모델 차원, openapi embeding model을 사용함. 정확하게 일치\n",
    "        metric=\"cosine\",  # 모델 메트릭, openapi embeding model 에서 사용하는 것 확인\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f9da98-f89c-4915-9039-2ac9346ec6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split하기\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정 (예: 1000자씩 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100,\n",
    "    # length_function=tiktoken_len,  # 토큰 기반 길이 측정    \n",
    "    length_function=len,  # 문자수   \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "# 문서를 분할\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220facf-56eb-43b2-8c2d-842a1ce6dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 완료: 100개 문서 업로드\n"
     ]
    }
   ],
   "source": [
    "# vector sotre에 저장(2시간정도 걸림)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "BATCH_SIZE = 100  # 한 번에 처리할 문서 수(최대 vector 수 1000개, 2MB 이내)\n",
    "\n",
    "for i in range(0, len(chunks), BATCH_SIZE):\n",
    "    batch_docs = chunks[i:i+BATCH_SIZE]\n",
    "    \n",
    "    # 첫 번째 배치로 벡터 스토어 생성\n",
    "    if i == 0:\n",
    "        vector_store = PineconeVectorStore.from_documents(\n",
    "            batch_docs,            # BATCH_SIZE 수 만큼의 chunk\n",
    "            embedding=embeddings,  # 임베딩 벡터로 변환\n",
    "            index_name=PINECONE_INDEX_NAME,   # index 이름\n",
    "            namespace=PINECONE_NAMESPACE      \n",
    "        )\n",
    "\n",
    "    # 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\n",
    "    else:\n",
    "        vector_store.add_documents(batch_docs)    \n",
    "    \n",
    "    print(f\"배치 {i//BATCH_SIZE + 1} 완료: {len(batch_docs)}개 문서 업로드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9972f54-af48-403c-ae05-faea7b38815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
