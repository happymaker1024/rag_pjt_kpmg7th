{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb338003-1bf9-4382-a5fd-ac6cc184bce3",
   "metadata": {},
   "source": [
    "# 와인 리뷰데이터 인덱싱\n",
    "- 벡터 DB : pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8dabfc6-8798-4757-9392-f3a68014448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load_dotenv(dotenv_path=\"../.env\")\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_NAMESPACE = os.getenv(\"PINECONE_NAMESPACE\")\n",
    "# PINECONE_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358dbe6-a1ba-484f-bd56-72df457689a3",
   "metadata": {},
   "source": [
    "# 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58dd0cd9-36dd-442e-b538-2e182e36429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "import os\n",
    "\n",
    "csv_path = os.path.abspath(\"wine_reviews/winemag-data-130k-v2.csv\")\n",
    "loader = CSVLoader(csv_path, encoding=\"latin-1\")   # 또는 \"ISO-8859-1\")\n",
    "docs = loader.load()\n",
    "\n",
    "# \"prepare/wine_reviews/winemag-data-130k-v2.csv\"\n",
    "# loader = CSVLoader('./wine_reviews/winemag-data-130k-v2.csv')\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d850e70-b01d-4cdb-9d55-643ee5dc319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "632eaad2-b69a-4350-ab43-b5d10d9cfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embedding 모델 객체 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=OPENAI_EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0009ceb-6548-4590-8c5d-fee226f02629",
   "metadata": {},
   "source": [
    "# Pinecone객체, index객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa26442f-a169-4697-93ed-872be3515814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Pinecone 클라이언트를 초기화(객체생성)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed0f6ace-2180-4d85-9bce-8a9bed25928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'wine-reviews' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# pinecone에 index list 가져오기\n",
    "existing_indexes = pc.list_indexes()\n",
    "\n",
    "# 이름만 추출\n",
    "index_names = [index['name'] for index in existing_indexes.indexes]\n",
    "# print(index_names)\n",
    "\n",
    "# index 이름이 존재 하지 않으면 생성\n",
    "if PINECONE_INDEX_NAME not in index_names:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=1536,  # 모델 차원, openapi embeding model을 사용함. 정확하게 일치\n",
    "        metric=\"cosine\",  # 모델 메트릭, openapi embeding model 에서 사용하는 것 확인\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33f9da98-f89c-4915-9039-2ac9346ec6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split하기\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정 (예: 1000자씩 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100,\n",
    "    # length_function=tiktoken_len,  # 토큰 기반 길이 측정    \n",
    "    length_function=len,  # 문자수   \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "# 문서를 분할\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c220facf-56eb-43b2-8c2d-842a1ce6dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 완료: 500개 문서 업로드\n",
      "배치 2 완료: 500개 문서 업로드\n",
      "배치 3 완료: 500개 문서 업로드\n",
      "배치 4 완료: 500개 문서 업로드\n",
      "배치 5 완료: 500개 문서 업로드\n",
      "배치 6 완료: 500개 문서 업로드\n",
      "배치 7 완료: 500개 문서 업로드\n",
      "배치 8 완료: 500개 문서 업로드\n",
      "배치 9 완료: 500개 문서 업로드\n",
      "배치 10 완료: 500개 문서 업로드\n",
      "배치 11 완료: 500개 문서 업로드\n",
      "배치 12 완료: 500개 문서 업로드\n",
      "배치 13 완료: 500개 문서 업로드\n",
      "배치 14 완료: 500개 문서 업로드\n",
      "배치 15 완료: 500개 문서 업로드\n",
      "배치 16 완료: 500개 문서 업로드\n",
      "배치 17 완료: 500개 문서 업로드\n",
      "배치 18 완료: 500개 문서 업로드\n",
      "배치 19 완료: 500개 문서 업로드\n",
      "배치 20 완료: 500개 문서 업로드\n",
      "배치 21 완료: 500개 문서 업로드\n",
      "배치 22 완료: 500개 문서 업로드\n",
      "배치 23 완료: 500개 문서 업로드\n",
      "배치 24 완료: 500개 문서 업로드\n",
      "배치 25 완료: 500개 문서 업로드\n",
      "배치 26 완료: 500개 문서 업로드\n",
      "배치 27 완료: 500개 문서 업로드\n",
      "배치 28 완료: 500개 문서 업로드\n",
      "배치 29 완료: 500개 문서 업로드\n",
      "배치 30 완료: 500개 문서 업로드\n",
      "배치 31 완료: 500개 문서 업로드\n",
      "배치 32 완료: 500개 문서 업로드\n",
      "배치 33 완료: 500개 문서 업로드\n",
      "배치 34 완료: 500개 문서 업로드\n",
      "배치 35 완료: 500개 문서 업로드\n",
      "배치 36 완료: 500개 문서 업로드\n",
      "배치 37 완료: 500개 문서 업로드\n",
      "배치 38 완료: 500개 문서 업로드\n",
      "배치 39 완료: 500개 문서 업로드\n",
      "배치 40 완료: 500개 문서 업로드\n",
      "배치 41 완료: 500개 문서 업로드\n",
      "배치 42 완료: 500개 문서 업로드\n",
      "배치 43 완료: 500개 문서 업로드\n",
      "배치 44 완료: 500개 문서 업로드\n",
      "배치 45 완료: 500개 문서 업로드\n",
      "배치 46 완료: 500개 문서 업로드\n",
      "배치 47 완료: 500개 문서 업로드\n",
      "배치 48 완료: 500개 문서 업로드\n",
      "배치 49 완료: 500개 문서 업로드\n",
      "배치 50 완료: 500개 문서 업로드\n",
      "배치 51 완료: 500개 문서 업로드\n",
      "배치 52 완료: 500개 문서 업로드\n",
      "배치 53 완료: 500개 문서 업로드\n",
      "배치 54 완료: 500개 문서 업로드\n",
      "배치 55 완료: 500개 문서 업로드\n",
      "배치 56 완료: 500개 문서 업로드\n",
      "배치 57 완료: 500개 문서 업로드\n",
      "배치 58 완료: 500개 문서 업로드\n",
      "배치 59 완료: 500개 문서 업로드\n",
      "배치 60 완료: 500개 문서 업로드\n",
      "배치 61 완료: 500개 문서 업로드\n",
      "배치 62 완료: 500개 문서 업로드\n",
      "배치 63 완료: 500개 문서 업로드\n",
      "배치 64 완료: 500개 문서 업로드\n",
      "배치 65 완료: 500개 문서 업로드\n",
      "배치 66 완료: 500개 문서 업로드\n",
      "배치 67 완료: 500개 문서 업로드\n",
      "배치 68 완료: 500개 문서 업로드\n",
      "배치 69 완료: 500개 문서 업로드\n",
      "배치 70 완료: 500개 문서 업로드\n",
      "배치 71 완료: 500개 문서 업로드\n",
      "배치 72 완료: 500개 문서 업로드\n",
      "배치 73 완료: 500개 문서 업로드\n",
      "배치 74 완료: 500개 문서 업로드\n",
      "배치 75 완료: 500개 문서 업로드\n",
      "배치 76 완료: 500개 문서 업로드\n",
      "배치 77 완료: 500개 문서 업로드\n",
      "배치 78 완료: 500개 문서 업로드\n",
      "배치 79 완료: 500개 문서 업로드\n",
      "배치 80 완료: 500개 문서 업로드\n",
      "배치 81 완료: 500개 문서 업로드\n",
      "배치 82 완료: 500개 문서 업로드\n",
      "배치 83 완료: 500개 문서 업로드\n",
      "배치 84 완료: 500개 문서 업로드\n",
      "배치 85 완료: 500개 문서 업로드\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m     vector_store \u001b[38;5;241m=\u001b[39m PineconeVectorStore\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     12\u001b[0m         batch_docs,            \u001b[38;5;66;03m# BATCH_SIZE 수 만큼의 chunk\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membeddings,  \u001b[38;5;66;03m# 임베딩 벡터로 변환\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         index_name\u001b[38;5;241m=\u001b[39mPINECONE_INDEX_NAME,   \u001b[38;5;66;03m# index 이름\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         namespace\u001b[38;5;241m=\u001b[39mPINECONE_NAMESPACE      \n\u001b[0;32m     16\u001b[0m     )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_docs\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m배치 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mBATCH_SIZE\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 문서 업로드\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:257\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    256\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:357\u001b[0m, in \u001b[0;36mPineconeVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, async_req, id_prefix, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m chunk_ids \u001b[38;5;241m=\u001b[39m ids[i : i \u001b[38;5;241m+\u001b[39m embedding_chunk_size]\n\u001b[0;32m    356\u001b[0m chunk_metadatas \u001b[38;5;241m=\u001b[39m metadatas[i : i \u001b[38;5;241m+\u001b[39m embedding_chunk_size]\n\u001b[1;32m--> 357\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m vector_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(chunk_ids, embeddings, chunk_metadatas))\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m async_req:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# Runs the pinecone upsert asynchronously.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:709\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# Unconditionally call _get_len_safe_embeddings to handle length safety.\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# This could be optimized to avoid double work when all texts are short enough.\u001b[39;00m\n\u001b[0;32m    708\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:576\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Make API call with this batch\u001b[39;00m\n\u001b[0;32m    575\u001b[0m batch_tokens \u001b[38;5;241m=\u001b[39m tokens[i:batch_end]\n\u001b[1;32m--> 576\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    578\u001b[0m     response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# vector sotre에 저장(2시간정도 걸림)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "BATCH_SIZE = 500  # 한 번에 처리할 문서 수(최대 vector 수 1000개, 2MB 이내)\n",
    "\n",
    "for i in range(0, len(chunks), BATCH_SIZE):\n",
    "    batch_docs = chunks[i:i+BATCH_SIZE]\n",
    "    \n",
    "    # 첫 번째 배치로 벡터 스토어 생성\n",
    "    if i == 0:\n",
    "        vector_store = PineconeVectorStore.from_documents(\n",
    "            batch_docs,            # BATCH_SIZE 수 만큼의 chunk\n",
    "            embedding=embeddings,  # 임베딩 벡터로 변환\n",
    "            index_name=PINECONE_INDEX_NAME,   # index 이름\n",
    "            namespace=PINECONE_NAMESPACE      \n",
    "        )\n",
    "\n",
    "    # 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\n",
    "    else:\n",
    "        vector_store.add_documents(batch_docs)    \n",
    "    \n",
    "    print(f\"배치 {i//BATCH_SIZE + 1} 완료: {len(batch_docs)}개 문서 업로드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9972f54-af48-403c-ae05-faea7b38815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "lc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
